#!/usr/bin/env python3
"""
Hyperliquid Tick Data Collector
Collects time-tagged prices, executed orders, and order book data via websockets
"""

import asyncio
import json
import time
from datetime import datetime
from collections import defaultdict, deque
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Any
import csv
import os
import threading
import pandas as pd
from concurrent.futures import ThreadPoolExecutor

from hyperliquid.info import Info
from hyperliquid.utils import constants


@dataclass
class TickData:
    """Base class for all tick data"""
    timestamp: float
    symbol: str
    exchange_timestamp: Optional[int] = None


@dataclass
class PriceData:
    """Price tick data"""
    timestamp: float
    symbol: str
    price: float
    size: float
    exchange_timestamp: Optional[int] = None
    side: Optional[str] = None  # 'bid' or 'ask' for BBO data


@dataclass
class TradeData:
    """Trade execution data"""
    timestamp: float
    symbol: str
    price: float
    size: float
    side: str  # 'buy' or 'sell'
    exchange_timestamp: Optional[int] = None
    trade_id: Optional[str] = None


@dataclass
class OrderBookLevel:
    """Order book level data"""
    price: float
    size: float


@dataclass
class OrderBookData:
    """Order book snapshot data"""
    timestamp: float
    symbol: str
    bids: List[OrderBookLevel]
    asks: List[OrderBookLevel]
    exchange_timestamp: Optional[int] = None
    sequence: Optional[int] = None


class DataStats:
    """Track data collection statistics"""
    def __init__(self):
        self.start_time = time.time()
        self.counters = defaultdict(int)
        self.last_update = time.time()
        self.recent_data = defaultdict(lambda: deque(maxlen=100))
    
    def update(self, data_type: str, data: Any = None):
        self.counters[data_type] += 1
        self.last_update = time.time()
        if data:
            self.recent_data[data_type].append(data)
    
    def get_summary(self) -> Dict[str, Any]:
        runtime = time.time() - self.start_time
        return {
            'runtime_seconds': runtime,
            'runtime_formatted': f"{runtime//3600:.0f}h {(runtime%3600)//60:.0f}m {runtime%60:.0f}s",
            'counters': dict(self.counters),
            'rates_per_minute': {k: v / (runtime / 60) for k, v in self.counters.items() if runtime > 0},
            'last_update': datetime.fromtimestamp(self.last_update).strftime('%H:%M:%S')
        }


class HyperliquidDataCollector:
    """Main data collector class"""
    
    def __init__(self, symbols: List[str], output_dir: str = "data", orderbook_depth: int = 20):
        self.symbols = symbols
        self.output_dir = output_dir
        self.orderbook_depth = orderbook_depth  # Configurable order book depth
        self.info = Info(constants.MAINNET_API_URL, skip_ws=False)
        self.stats = DataStats()
        self.subscription_ids = []
        
        # Lock for thread-safe buffer access
        self.lock = threading.Lock()
        
        # Create separate buffers for each symbol
        self.data_buffers = {}
        for symbol in symbols:
            self.data_buffers[symbol] = {
                'prices': deque(maxlen=100000),
                'trades': deque(maxlen=100000),
                'orderbooks': deque(maxlen=10000)
            }
        
        self.running = False
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # Ensure output directory exists and organize by symbol/type
        self._init_storage()
    
    def _init_storage(self):
        """Initialize directory structure for data storage"""
        for symbol in self.symbols:
            for dtype in ['prices', 'trades', 'orderbooks']:
                path = os.path.join(self.output_dir, symbol, dtype)
                os.makedirs(path, exist_ok=True)
    
    def _write_to_parquet(self, symbol: str, dtype: str, data: List[Any]):
        """Write data to Parquet file using Pandas"""
        if not data:
            return

        try:
            # Convert to DataFrame
            # For list of objects (TickData, TradeData etc) or list of dicts
            if len(data) > 0 and not isinstance(data[0], dict):
                df = pd.DataFrame([asdict(item) for item in data])
            else:
                df = pd.DataFrame(data)
            
            # Generate filename with timestamp
            timestamp = int(time.time() * 1000)
            filename = f"{dtype}_{timestamp}.parquet"
            file_path = os.path.join(self.output_dir, symbol, dtype, filename)
            
            # Write to parquet
            df.to_parquet(file_path, engine='pyarrow', index=False, compression='zstd')
            
        except Exception as e:
            print(f"Error writing to Parquet {symbol}/{dtype}: {e}")

    # _handle_bbo_data, _handle_trade_data, _handle_orderbook_data remain unchanged
    
    def _handle_bbo_data(self, data: Dict[str, Any]):
        """Handle best bid/offer data"""
        try:
            timestamp = time.time()
            
            # Handle channel-based format
            if 'channel' in data and data['channel'] == 'bbo' and 'data' in data:
                bbo_data = data['data']
                symbol = bbo_data.get('coin', 'UNKNOWN')
                
                # BBO format: bbo array with [bid, ask]
                if 'bbo' in bbo_data and len(bbo_data['bbo']) >= 2:
                    bid_info = bbo_data['bbo'][0]  # First element is bid
                    ask_info = bbo_data['bbo'][1]  # Second element is ask
                    
                    # Create bid data
                    bid_data = {
                        'timestamp': timestamp,
                        'price': float(bid_info['px']),
                        'size': float(bid_info['sz']),
                        'side': 'bid',
                        'exchange_timestamp': bbo_data.get('time')
                    }
                    
                    # Create ask data
                    ask_data = {
                        'timestamp': timestamp,
                        'price': float(ask_info['px']),
                        'size': float(ask_info['sz']),
                        'side': 'ask',
                        'exchange_timestamp': bbo_data.get('time')
                    }

                    with self.lock:
                        self.data_buffers[symbol]['prices'].append(bid_data)
                        self.data_buffers[symbol]['prices'].append(ask_data)
                
                self.stats.update('bbo_updates')
            else:
                # Direct format fallback
                symbol = data.get('coin', 'UNKNOWN')
                
                with self.lock:
                    if 'bid' in data and data['bid']:
                        bid_data = {
                            'timestamp': timestamp,
                            'price': float(data['bid']['px']),
                            'size': float(data['bid']['sz']),
                            'side': 'bid',
                            'exchange_timestamp': data.get('time')
                        }
                        self.data_buffers[symbol]['prices'].append(bid_data)
                    
                    if 'ask' in data and data['ask']:
                        ask_data = {
                            'timestamp': timestamp,
                            'price': float(data['ask']['px']),
                            'size': float(data['ask']['sz']),
                            'side': 'ask',
                            'exchange_timestamp': data.get('time')
                        }
                        self.data_buffers[symbol]['prices'].append(ask_data)
                
                self.stats.update('bbo_updates')
        except Exception as e:
            print(f"Error handling BBO data: {e}")
    
    def _handle_trade_data(self, data: Dict[str, Any]):
        """Handle trade data"""
        try:
            timestamp = time.time()
            
            # Handle channel-based format
            if 'channel' in data and data['channel'] == 'trades' and 'data' in data:
                trades = data['data']
                for trade in trades:
                    symbol = trade.get('coin', 'UNKNOWN')
                    # Convert A/B to buy/sell
                    side = 'sell' if trade['side'] == 'A' else 'buy'
                    
                    trade_data = {
                        'timestamp': timestamp,
                        'price': float(trade['px']),
                        'size': float(trade['sz']),
                        'side': side,
                        'trade_id': str(trade.get('tid')),
                        'exchange_timestamp': trade.get('time')
                    }
                    with self.lock:
                        self.data_buffers[symbol]['trades'].append(trade_data)
                
                self.stats.update('trades', len(trades))
            else:
                # Direct format fallback  
                if isinstance(data, list):
                    trades = data
                else:
                    trades = [data]
                    
                for trade in trades:
                    symbol = trade.get('coin', 'UNKNOWN')
                    side = 'sell' if trade['side'] == 'A' else 'buy'
                    
                    trade_data = {
                        'timestamp': timestamp,
                        'price': float(trade['px']),
                        'size': float(trade['sz']),
                        'side': side,
                        'trade_id': str(trade.get('tid')),
                        'exchange_timestamp': trade.get('time')
                    }
                    with self.lock:
                        self.data_buffers[symbol]['trades'].append(trade_data)
                
                self.stats.update('trades', len(trades))
        except Exception as e:
            print(f"Error handling trade data: {e}")
    
    def _handle_orderbook_data(self, data: Dict[str, Any]):
        """Handle order book data"""
        try:
            timestamp = time.time()
            
            # Handle channel-based format
            if 'channel' in data and data['channel'] == 'l2Book' and 'data' in data:
                book_data = data['data']
                symbol = book_data.get('coin', 'UNKNOWN')
                
                # Parse bids and asks
                bids = []
                asks = []
                
                if 'levels' in book_data and len(book_data['levels']) >= 2:
                    # levels[0] is bids array, levels[1] is asks array
                    bids_array = book_data['levels'][0]
                    asks_array = book_data['levels'][1]
                    
                    # Parse bids
                    for bid in bids_array:
                        bids.append(OrderBookLevel(price=float(bid['px']), size=float(bid['sz'])))
                    
                    # Parse asks  
                    for ask in asks_array:
                        asks.append(OrderBookLevel(price=float(ask['px']), size=float(ask['sz'])))
                
                # Prepare data for CSV (flatten configurable depth levels)
                csv_row = {
                    'timestamp': timestamp,
                    'sequence': book_data.get('time'),
                    'exchange_timestamp': book_data.get('time')
                }
                
                for i in range(self.orderbook_depth):
                    if i < len(bids):
                        csv_row[f'bid_price_{i}'] = bids[i].price
                        csv_row[f'bid_size_{i}'] = bids[i].size
                    else:
                        csv_row[f'bid_price_{i}'] = None
                        csv_row[f'bid_size_{i}'] = None
                    
                    if i < len(asks):
                        csv_row[f'ask_price_{i}'] = asks[i].price
                        csv_row[f'ask_size_{i}'] = asks[i].size
                    else:
                        csv_row[f'ask_price_{i}'] = None
                        csv_row[f'ask_size_{i}'] = None
                
                with self.lock:
                    self.data_buffers[symbol]['orderbooks'].append(csv_row)
                self.stats.update('orderbook_updates')
            else:
                # Direct format fallback
                symbol = data.get('coin', 'UNKNOWN')
                
                # Parse bids and asks
                bids = []
                asks = []
                
                if 'levels' in data and len(data['levels']) >= 2:
                    # levels[0] is bids array, levels[1] is asks array
                    bids_array = data['levels'][0]
                    asks_array = data['levels'][1]
                    
                    # Parse bids
                    for bid in bids_array:
                        bids.append(OrderBookLevel(price=float(bid['px']), size=float(bid['sz'])))
                    
                    # Parse asks  
                    for ask in asks_array:
                        asks.append(OrderBookLevel(price=float(ask['px']), size=float(ask['sz'])))
                
                # Prepare data for CSV (flatten configurable depth levels)
                csv_row = {
                    'timestamp': timestamp,
                    'sequence': data.get('time'),
                    'exchange_timestamp': data.get('time')
                }
                
                for i in range(self.orderbook_depth):
                    if i < len(bids):
                        csv_row[f'bid_price_{i}'] = bids[i].price
                        csv_row[f'bid_size_{i}'] = bids[i].size
                    else:
                        csv_row[f'bid_price_{i}'] = None
                        csv_row[f'bid_size_{i}'] = None
                    
                    if i < len(asks):
                        csv_row[f'ask_price_{i}'] = asks[i].price
                        csv_row[f'ask_size_{i}'] = asks[i].size
                    else:
                        csv_row[f'ask_price_{i}'] = None
                        csv_row[f'ask_size_{i}'] = None
                
                with self.lock:
                    self.data_buffers[symbol]['orderbooks'].append(csv_row)
                self.stats.update('orderbook_updates')
            
        except Exception as e:
            print(f"Error handling order book data: {e}")
    
    def _flush_buffers(self):
        """Flush data buffers to Parquet files"""
        try:
            # First, snapshot and clear buffers within the lock
            data_to_write = {}
            
            with self.lock:
                for symbol in self.symbols:
                    symbol_buffers = self.data_buffers[symbol]
                    data_to_write[symbol] = {}
                    
                    if symbol_buffers['prices']:
                        data_to_write[symbol]['prices'] = list(symbol_buffers['prices'])
                        symbol_buffers['prices'].clear()
                    
                    if symbol_buffers['trades']:
                        data_to_write[symbol]['trades'] = list(symbol_buffers['trades'])
                        symbol_buffers['trades'].clear()
                        
                    if symbol_buffers['orderbooks']:
                        data_to_write[symbol]['orderbooks'] = list(symbol_buffers['orderbooks'])
                        symbol_buffers['orderbooks'].clear()
            
            # Then write to files (outside the lock)
            flushed_count = 0
            for symbol, buffers in data_to_write.items():
                if 'prices' in buffers:
                    self.executor.submit(self._write_to_parquet, symbol, 'prices', buffers['prices'])
                    flushed_count += 1
                
                if 'trades' in buffers:
                    self.executor.submit(self._write_to_parquet, symbol, 'trades', buffers['trades'])
                    flushed_count += 1
                
                if 'orderbooks' in buffers:
                    self.executor.submit(self._write_to_parquet, symbol, 'orderbooks', buffers['orderbooks'])
                    flushed_count += 1
            
            if flushed_count > 0:
                print(f"Flushed buffers for {flushed_count} data types across symbols")
                
        except Exception as e:
            print(f"Error flushing buffers: {e}")
    
    def _print_summary(self):
        """Print data collection summary"""
        summary = self.stats.get_summary()
        print("\n" + "="*60)
        print(f"DATA COLLECTION SUMMARY - {summary['last_update']}")
        print("="*60)
        print(f"Runtime: {summary['runtime_formatted']}")
        print(f"Data collected:")
        for data_type, count in summary['counters'].items():
            rate = summary['rates_per_minute'].get(data_type, 0)
            print(f"  {data_type}: {count:,} ({rate:.1f}/min)")
        
        print(f"\nBuffer sizes by symbol:")
        
        # Calculate buffer sizes with lock to ensure consistency
        with self.lock:
            for symbol in self.symbols:
                symbol_buffers = self.data_buffers[symbol]
                total_buffered = sum(len(buffer) for buffer in symbol_buffers.values())
                print(f"  {symbol}: {total_buffered} ({len(symbol_buffers['prices'])} prices, {len(symbol_buffers['trades'])} trades, {len(symbol_buffers['orderbooks'])} orderbooks)")
        
        print("="*60)
    
    def start_collection(self):
        """Start data collection"""
        print(f"Starting Hyperliquid data collection for symbols: {self.symbols}")
        print(f"Output directory: {self.output_dir}")
        
        self.running = True
        
        try:
            # Subscribe to data feeds for each symbol
            for symbol in self.symbols:
                print(f"Subscribing to data feeds for {symbol}...")
                
                # Subscribe to best bid/offer
                bbo_id = self.info.subscribe(
                    {"type": "bbo", "coin": symbol},
                    self._handle_bbo_data
                )
                self.subscription_ids.append(bbo_id)
                
                # Subscribe to trades
                trades_id = self.info.subscribe(
                    {"type": "trades", "coin": symbol},
                    self._handle_trade_data
                )
                self.subscription_ids.append(trades_id)
                
                # Subscribe to order book
                l2book_id = self.info.subscribe(
                    {"type": "l2Book", "coin": symbol},
                    self._handle_orderbook_data
                )
                self.subscription_ids.append(l2book_id)
            
            print(f"Subscribed to {len(self.subscription_ids)} data feeds")
            
            # Start background tasks
            flush_thread = threading.Thread(target=self._periodic_flush, daemon=True)
            flush_thread.start()
            
            summary_thread = threading.Thread(target=self._periodic_summary, daemon=True)
            summary_thread.start()
            
            # Keep running
            print("Data collection started. Press Ctrl+C to stop.")
            while self.running:
                time.sleep(1)
                
        except KeyboardInterrupt:
            print("\nShutting down...")
            self.stop_collection()
        except Exception as e:
            print(f"Error during data collection: {e}")
            self.stop_collection()
    
    def _periodic_flush(self):
        """Periodically flush buffers to disk"""
        while self.running:
            time.sleep(10)  # Flush every 10 seconds
            self._flush_buffers()
    
    def _periodic_summary(self):
        """Periodically print collection summary"""
        while self.running:
            time.sleep(30)  # Print summary every 30 seconds
            if self.running:
                self._print_summary()
    
    def stop_collection(self):
        """Stop data collection"""
        self.running = False
        
        # Unsubscribe from all feeds - SDK Info class manages this mostly via stop() but explicit unsubscribe would be here if needed
        # Since we are shutting down, we'll rely on disconnect_websocket
        
        # Final flush
        self._flush_buffers()
        
        # Wait for executor to finish
        self.executor.shutdown(wait=True)
        
        # Disconnect websocket
        try:
            self.info.disconnect_websocket()
        except Exception as e:
            print(f"Error disconnecting websocket: {e}")
        
        # Final summary
        self._print_summary()
        print(f"\nData files saved in: {self.output_dir}")


def main():
    """Main function"""
    # Configuration
    SYMBOLS = ["ETH"]  # Add more symbols as needed
    OUTPUT_DIR = "HL_data"
    ORDERBOOK_DEPTH = 20  # Number of order book levels to capture (default: 20)
    
    print("Hyperliquid Tick Data Collector")
    print("================================")
    print(f"Order book depth: {ORDERBOOK_DEPTH} levels")
    
    # Create collector with configurable order book depth
    collector = HyperliquidDataCollector(SYMBOLS, OUTPUT_DIR, orderbook_depth=ORDERBOOK_DEPTH)
    
    # Start collection
    collector.start_collection()


if __name__ == "__main__":
    main()
